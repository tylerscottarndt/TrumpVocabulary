{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "class Metrics:\n",
    "    def __init__(self, df):\n",
    "        self.df = pd.read_pickle(df)\n",
    "        self.union_speeches = []\n",
    "        self.rally_speeches = []\n",
    "        \n",
    "    def find_avg_word_length(self):\n",
    "        average_res = []\n",
    "        rally = self._get_speeches_list_from_df(self.df,1)\n",
    "        union = self._get_speeches_list_from_df(self.df,0)\n",
    "        self.rally_speeches.append(rally)\n",
    "        self.union_speeches.append(union)\n",
    "        word_count = 0\n",
    "        total_characters = 0\n",
    "        for speech_list in [rally, union]:\n",
    "            for speech in speech_list:\n",
    "                word_count += len(speech.split())\n",
    "                total_characters += len(speech) - speech.count(' ')\n",
    "                \n",
    "            avg_word_length = total_characters / word_count\n",
    "            average_res.append(round(avg_word_length,2))\n",
    "            \n",
    "            \n",
    "        return average_res\n",
    "\n",
    "\n",
    "    def _get_speeches_list_from_df(self, df, attr_val):\n",
    "        df_speeches = df.loc[df['type'] == attr_val]\n",
    "        speeches_list = df_speeches['transcript'].tolist()\n",
    "\n",
    "        return speeches_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/daniel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def preprocess_text(sen):\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sen)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class Compress:\n",
    "    def save_as_npz(self,df,npz_name=None,tran_data='transcript',label='type'):\n",
    "        X = []\n",
    "        y = np.array(df[label])\n",
    "        sentences = np.array(df[tran_data])\n",
    "        for sen in sentences:\n",
    "            X.append(preprocess_text(sen))\n",
    "        self._train_test_split(np.array(X), np.array(y), npz_filename=npz_name)\n",
    "        \n",
    "        \n",
    "\n",
    "    def _train_test_split(self,X,y,npz_filename=''+'.npz',test_size=0.2, random_state=42):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "        print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "        np.savez_compressed(npz_filename,\n",
    "                        X_train=X_train,\n",
    "                        y_train=y_train,\n",
    "                        X_test=X_test,\n",
    "                        y_test=y_test)\n",
    "        print(\"Saved {} as .npz\".format(npz_filename))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.58, 5.67] [4.25, 4.31]\n",
      "[5.79, 6.04] [4.3, 4.53]\n"
     ]
    }
   ],
   "source": [
    "trump_snippits = Metrics(\"TRUMP_SNIPPETS_DF.pickle\")\n",
    "trump_speeches = Metrics('trump_speeches_df.pickle')\n",
    "obama_speeches = Metrics('obama_speeches_df.pickle')\n",
    "obama_snippits = Metrics('OBAMA_SNIPPETS_DF.pickle')\n",
    "\n",
    "\n",
    "print(trump_snippits.find_avg_word_length(), trump_speeches.find_avg_word_length())\n",
    "print(obama_snippits.find_avg_word_length(), obama_speeches.find_avg_word_length())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trump_data = pickle.load(open(\"TRUMP_SNIPPETS_DF.pickle\", \"rb\" ))\n",
    "obama_data = pickle.load(open(\"OBAMA_SNIPPETS_DF.pickle\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f852aa27f50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x='type', data=trump_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f852a16f210>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='type', data=obama_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1941,) (1941,) (486,) (486,)\n",
      "Saved TRUMP_SPLIT_DATA as .npz\n",
      "(1036,) (1036,) (259,) (259,)\n",
      "Saved OBAMA_SPLIT_DATA as .npz\n"
     ]
    }
   ],
   "source": [
    "compress = Compress()\n",
    "compress.save_as_npz(trump_data, npz_name='TRUMP_SPLIT_DATA')\n",
    "compress.save_as_npz(obama_data, npz_name='OBAMA_SPLIT_DATA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "china many us thats got going thats treat us really badly many others many many others india tariffs us probably higher nation anywhere world tariffs products much india working called prime minister modi said mr prime minister fair weve got change weve got change weve got change talking seriously talking lot places\n"
     ]
    }
   ],
   "source": [
    "class load_file:\n",
    "    def __init__(self, file):\n",
    "        self.file = file\n",
    "\n",
    "    def get_data(self):\n",
    "        hal = np.load(self.file)\n",
    "        X_train, y_train, X_test, y_test = [hal[f] for f in hal.files]\n",
    "        return X_train, y_train, X_test, y_test\n",
    "\n",
    "\n",
    "df = load_file('dataset_split_transcripts.npz')\n",
    "X_train, y_train, X_test, y_test = df.get_data()\n",
    "# Load split data\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab_size = 500\n",
    "\n",
    "X_train = [one_hot(d, vocab_size,filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',lower=True, split=' ') for d in X_train]\n",
    "X_test = [one_hot(d, vocab_size,filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~',lower=True, split=' ') for d in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 25\n",
    "X_train = pad_sequences(X_train, maxlen=max_length, padding='pre')\n",
    "X_test = pad_sequences(X_test, maxlen=max_length, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 25, 8)             4000      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 4,201\n",
      "Trainable params: 4,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 1559 samples, validate on 390 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1559/1559 [==============================] - 1s 482us/step - loss: 0.6605 - acc: 0.7877 - val_loss: 0.6157 - val_acc: 0.8385\n",
      "Epoch 2/50\n",
      "1559/1559 [==============================] - 0s 128us/step - loss: 0.5147 - acc: 0.8640 - val_loss: 0.4470 - val_acc: 0.8385\n",
      "Epoch 3/50\n",
      "1559/1559 [==============================] - 0s 128us/step - loss: 0.3624 - acc: 0.8640 - val_loss: 0.3770 - val_acc: 0.8385\n",
      "Epoch 4/50\n",
      "1559/1559 [==============================] - 0s 125us/step - loss: 0.3103 - acc: 0.8640 - val_loss: 0.3542 - val_acc: 0.8385\n",
      "Epoch 5/50\n",
      "1559/1559 [==============================] - 0s 129us/step - loss: 0.2813 - acc: 0.8640 - val_loss: 0.3329 - val_acc: 0.8385\n",
      "Epoch 6/50\n",
      "1559/1559 [==============================] - 0s 137us/step - loss: 0.2538 - acc: 0.8672 - val_loss: 0.3123 - val_acc: 0.8436\n",
      "Epoch 7/50\n",
      "1559/1559 [==============================] - 0s 125us/step - loss: 0.2277 - acc: 0.8781 - val_loss: 0.2936 - val_acc: 0.8513\n",
      "Epoch 8/50\n",
      "1559/1559 [==============================] - 0s 137us/step - loss: 0.2037 - acc: 0.8980 - val_loss: 0.2780 - val_acc: 0.8590\n",
      "Epoch 9/50\n",
      "1559/1559 [==============================] - 0s 131us/step - loss: 0.1819 - acc: 0.9192 - val_loss: 0.2647 - val_acc: 0.8718\n",
      "Epoch 10/50\n",
      "1559/1559 [==============================] - 0s 127us/step - loss: 0.1632 - acc: 0.9365 - val_loss: 0.2547 - val_acc: 0.8795\n",
      "Epoch 11/50\n",
      "1559/1559 [==============================] - 0s 128us/step - loss: 0.1473 - acc: 0.9545 - val_loss: 0.2491 - val_acc: 0.8897\n",
      "Epoch 12/50\n",
      "1559/1559 [==============================] - 0s 128us/step - loss: 0.1337 - acc: 0.9615 - val_loss: 0.2450 - val_acc: 0.8949\n",
      "Epoch 13/50\n",
      "1559/1559 [==============================] - 0s 125us/step - loss: 0.1218 - acc: 0.9641 - val_loss: 0.2432 - val_acc: 0.8974\n",
      "Epoch 14/50\n",
      "1559/1559 [==============================] - 0s 141us/step - loss: 0.1112 - acc: 0.9686 - val_loss: 0.2425 - val_acc: 0.8974\n",
      "Epoch 15/50\n",
      "1559/1559 [==============================] - 0s 132us/step - loss: 0.1018 - acc: 0.9763 - val_loss: 0.2428 - val_acc: 0.8897\n",
      "Epoch 16/50\n",
      "1559/1559 [==============================] - 0s 129us/step - loss: 0.0934 - acc: 0.9788 - val_loss: 0.2451 - val_acc: 0.8872\n",
      "Epoch 17/50\n",
      "1559/1559 [==============================] - 0s 139us/step - loss: 0.0856 - acc: 0.9795 - val_loss: 0.2473 - val_acc: 0.8846\n",
      "Epoch 18/50\n",
      "1559/1559 [==============================] - 0s 126us/step - loss: 0.0782 - acc: 0.9833 - val_loss: 0.2497 - val_acc: 0.8769\n",
      "Epoch 19/50\n",
      "1559/1559 [==============================] - 0s 140us/step - loss: 0.0716 - acc: 0.9872 - val_loss: 0.2534 - val_acc: 0.8795\n",
      "Epoch 20/50\n",
      "1559/1559 [==============================] - 0s 130us/step - loss: 0.0656 - acc: 0.9878 - val_loss: 0.2580 - val_acc: 0.8769\n",
      "Epoch 21/50\n",
      "1559/1559 [==============================] - 0s 135us/step - loss: 0.0602 - acc: 0.9891 - val_loss: 0.2612 - val_acc: 0.8795\n",
      "Epoch 22/50\n",
      "1559/1559 [==============================] - 0s 133us/step - loss: 0.0551 - acc: 0.9936 - val_loss: 0.2661 - val_acc: 0.8795\n",
      "Epoch 23/50\n",
      "1559/1559 [==============================] - 0s 128us/step - loss: 0.0506 - acc: 0.9968 - val_loss: 0.2713 - val_acc: 0.8795\n",
      "Epoch 24/50\n",
      "1559/1559 [==============================] - 0s 124us/step - loss: 0.0463 - acc: 0.9968 - val_loss: 0.2755 - val_acc: 0.8744\n",
      "Epoch 25/50\n",
      "1559/1559 [==============================] - 0s 126us/step - loss: 0.0423 - acc: 0.9974 - val_loss: 0.2805 - val_acc: 0.8769\n",
      "Epoch 26/50\n",
      "1559/1559 [==============================] - 0s 137us/step - loss: 0.0388 - acc: 0.9994 - val_loss: 0.2856 - val_acc: 0.8769\n",
      "Epoch 27/50\n",
      "1559/1559 [==============================] - 0s 137us/step - loss: 0.0357 - acc: 0.9994 - val_loss: 0.2909 - val_acc: 0.8769\n",
      "Epoch 28/50\n",
      "1559/1559 [==============================] - 0s 130us/step - loss: 0.0328 - acc: 0.9994 - val_loss: 0.2958 - val_acc: 0.8769\n",
      "Epoch 29/50\n",
      "1559/1559 [==============================] - 0s 127us/step - loss: 0.0303 - acc: 0.9994 - val_loss: 0.3008 - val_acc: 0.8769\n",
      "Epoch 30/50\n",
      "1559/1559 [==============================] - 0s 125us/step - loss: 0.0278 - acc: 1.0000 - val_loss: 0.3052 - val_acc: 0.8744\n",
      "Epoch 31/50\n",
      "1559/1559 [==============================] - 0s 124us/step - loss: 0.0257 - acc: 1.0000 - val_loss: 0.3102 - val_acc: 0.8744\n",
      "Epoch 32/50\n",
      "1559/1559 [==============================] - 0s 123us/step - loss: 0.0238 - acc: 1.0000 - val_loss: 0.3135 - val_acc: 0.8744\n",
      "Epoch 33/50\n",
      "1559/1559 [==============================] - 0s 132us/step - loss: 0.0219 - acc: 1.0000 - val_loss: 0.3197 - val_acc: 0.8744\n",
      "Epoch 34/50\n",
      "1559/1559 [==============================] - 0s 130us/step - loss: 0.0203 - acc: 1.0000 - val_loss: 0.3245 - val_acc: 0.8744\n",
      "Epoch 35/50\n",
      "1559/1559 [==============================] - 0s 131us/step - loss: 0.0188 - acc: 1.0000 - val_loss: 0.3293 - val_acc: 0.8718\n",
      "Epoch 36/50\n",
      "1559/1559 [==============================] - 0s 129us/step - loss: 0.0175 - acc: 1.0000 - val_loss: 0.3338 - val_acc: 0.8718\n",
      "Epoch 37/50\n",
      "1559/1559 [==============================] - 0s 126us/step - loss: 0.0162 - acc: 1.0000 - val_loss: 0.3384 - val_acc: 0.8718\n",
      "Epoch 38/50\n",
      "1559/1559 [==============================] - 0s 129us/step - loss: 0.0151 - acc: 1.0000 - val_loss: 0.3425 - val_acc: 0.8692\n",
      "Epoch 39/50\n",
      "1559/1559 [==============================] - 0s 131us/step - loss: 0.0141 - acc: 1.0000 - val_loss: 0.3474 - val_acc: 0.8718\n",
      "Epoch 40/50\n",
      "1559/1559 [==============================] - 0s 139us/step - loss: 0.0131 - acc: 1.0000 - val_loss: 0.3508 - val_acc: 0.8718\n",
      "Epoch 41/50\n",
      "1559/1559 [==============================] - 0s 134us/step - loss: 0.0123 - acc: 1.0000 - val_loss: 0.3555 - val_acc: 0.8718\n",
      "Epoch 42/50\n",
      "1559/1559 [==============================] - 0s 128us/step - loss: 0.0115 - acc: 1.0000 - val_loss: 0.3602 - val_acc: 0.8744\n",
      "Epoch 43/50\n",
      "1559/1559 [==============================] - 0s 127us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 0.3640 - val_acc: 0.8744\n",
      "Epoch 44/50\n",
      "1559/1559 [==============================] - 0s 125us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 0.3676 - val_acc: 0.8744\n",
      "Epoch 45/50\n",
      "1559/1559 [==============================] - 0s 128us/step - loss: 0.0095 - acc: 1.0000 - val_loss: 0.3722 - val_acc: 0.8744\n",
      "Epoch 46/50\n",
      "1559/1559 [==============================] - 0s 131us/step - loss: 0.0089 - acc: 1.0000 - val_loss: 0.3764 - val_acc: 0.8744\n",
      "Epoch 47/50\n",
      "1559/1559 [==============================] - 0s 127us/step - loss: 0.0084 - acc: 1.0000 - val_loss: 0.3800 - val_acc: 0.8744\n",
      "Epoch 48/50\n",
      "1559/1559 [==============================] - 0s 128us/step - loss: 0.0079 - acc: 1.0000 - val_loss: 0.3833 - val_acc: 0.8744\n",
      "Epoch 49/50\n",
      "1559/1559 [==============================] - 0s 131us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 0.3870 - val_acc: 0.8744\n",
      "Epoch 50/50\n",
      "1559/1559 [==============================] - 0s 126us/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.3912 - val_acc: 0.8744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f84d35606d0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 8, input_length=max_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1949/1949 [==============================] - 0s 54us/step\n",
      "Training Accuracy is 97.48588800430298\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=1)\n",
    "print('Training Accuracy is {}'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 0s 51us/step\n",
      "Testing Accuracy is 90.77869057655334 \n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test,y_test)\n",
    "print('Testing Accuracy is {} '.format(accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
